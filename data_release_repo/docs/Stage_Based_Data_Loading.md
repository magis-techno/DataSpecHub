# é˜¶æ®µåŒ–æ•°æ®åŠ è½½æœºåˆ¶

ä½œè€…ï¼š
ç‰ˆæœ¬ï¼šv1.0.0
æ›´æ–°æ—¶é—´ï¼š2025-09-23

## æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰äº†æ”¯æŒä¸åŒè®­ç»ƒé˜¶æ®µåŠ è½½ä¸åŒæ•°æ®é›†çš„æœºåˆ¶ï¼Œé€šè¿‡é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡å®ç°æ— ä»£ç ä¿®æ”¹çš„æ•°æ®åˆ‡æ¢ã€‚

## èƒŒæ™¯éœ€æ±‚

åœ¨æœºå™¨å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸åŒé˜¶æ®µå¯èƒ½éœ€è¦ä¸åŒçš„æ•°æ®ï¼š
- **é¢„è®­ç»ƒé˜¶æ®µ**: å¤§è§„æ¨¡åŸºç¡€æ•°æ®é›†
- **å¾®è°ƒé˜¶æ®µ**: ç‰¹å®šåœºæ™¯çš„ç²¾é€‰æ•°æ®é›†  
- **è¯„ä¼°é˜¶æ®µ**: æ ‡å‡†æµ‹è¯•æ•°æ®é›†
- **åœ¨çº¿å­¦ä¹ é˜¶æ®µ**: å®æ—¶æ”¶é›†çš„æ•°æ®é›†
- **A/Bæµ‹è¯•é˜¶æ®µ**: å¯¹æ¯”å®éªŒæ•°æ®é›†

## ğŸ¯ è®¾è®¡æ–¹æ¡ˆ

### 1. é˜¶æ®µåŒ–é…ç½®æ–‡ä»¶ç»“æ„

```
data_release_repo/
â”œâ”€â”€ training_dataset.json              # é»˜è®¤æ•°æ®é›†é…ç½®
â”œâ”€â”€ stages/                            # é˜¶æ®µåŒ–é…ç½®ç›®å½•
â”‚   â”œâ”€â”€ pretraining.json              # é¢„è®­ç»ƒé˜¶æ®µ
â”‚   â”œâ”€â”€ finetuning.json               # å¾®è°ƒé˜¶æ®µ
â”‚   â”œâ”€â”€ evaluation.json               # è¯„ä¼°é˜¶æ®µ
â”‚   â”œâ”€â”€ online_learning.json          # åœ¨çº¿å­¦ä¹ é˜¶æ®µ
â”‚   â””â”€â”€ ab_testing/                    # A/Bæµ‹è¯•ç›®å½•
â”‚       â”œâ”€â”€ variant_a.json
â”‚       â””â”€â”€ variant_b.json
â”œâ”€â”€ stage_config.yaml                 # é˜¶æ®µé…ç½®æ˜ å°„
â””â”€â”€ active_stage.yaml                 # å½“å‰æ¿€æ´»é˜¶æ®µ
```

### 2. é˜¶æ®µé…ç½®æ˜ å°„æ–‡ä»¶

**stage_config.yaml**:
```yaml
# é˜¶æ®µå®šä¹‰å’Œé…ç½®
stages:
  pretraining:
    name: "é¢„è®­ç»ƒé˜¶æ®µ"
    description: "å¤§è§„æ¨¡åŸºç¡€æ•°æ®é›†è®­ç»ƒ"
    config_file: "stages/pretraining.json"
    priority: 1
    auto_switch_conditions:
      - epoch: 0
        condition: "start"
    
  finetuning:
    name: "å¾®è°ƒé˜¶æ®µ" 
    description: "ç‰¹å®šåœºæ™¯ç²¾ç»†åŒ–è®­ç»ƒ"
    config_file: "stages/finetuning.json"
    priority: 2
    auto_switch_conditions:
      - epoch: 50
        condition: "pretraining_complete"
    
  evaluation:
    name: "è¯„ä¼°é˜¶æ®µ"
    description: "æ¨¡å‹æ€§èƒ½è¯„ä¼°"
    config_file: "stages/evaluation.json"
    priority: 3
    auto_switch_conditions:
      - epoch: 100
        condition: "training_complete"
    
  online_learning:
    name: "åœ¨çº¿å­¦ä¹ é˜¶æ®µ"
    description: "å¢é‡å­¦ä¹ å’Œæ¨¡å‹æ›´æ–°"
    config_file: "stages/online_learning.json"
    priority: 4
    trigger_mode: "manual"  # æ‰‹åŠ¨è§¦å‘
    
  ab_testing:
    name: "A/Bæµ‹è¯•é˜¶æ®µ"
    description: "å¯¹æ¯”å®éªŒæ•°æ®é›†"
    variants:
      variant_a:
        config_file: "stages/ab_testing/variant_a.json"
        weight: 0.5
      variant_b:
        config_file: "stages/ab_testing/variant_b.json"
        weight: 0.5

# é»˜è®¤é˜¶æ®µ
default_stage: "pretraining"

# é˜¶æ®µåˆ‡æ¢ç­–ç•¥
switch_strategy:
  mode: "auto"  # auto | manual | hybrid
  check_interval: 10  # æ£€æŸ¥é—´éš”(epoch)
  fallback_stage: "pretraining"
```

### 3. æ¿€æ´»é˜¶æ®µçŠ¶æ€æ–‡ä»¶

**active_stage.yaml**:
```yaml
# å½“å‰æ¿€æ´»çš„é˜¶æ®µ
current_stage: "pretraining"
current_variant: null  # A/Bæµ‹è¯•æ—¶ä½¿ç”¨
activated_at: "2025-09-23 10:30:00"
activated_by: "system"  # system | user | scheduler
switch_reason: "training_start"

# å†å²è®°å½•
history:
  - stage: "pretraining"
    activated_at: "2025-09-23 10:30:00"
    deactivated_at: null
    duration: null
    reason: "training_start"

# ä¸‹ä¸€é˜¶æ®µé¢„æµ‹
next_stage:
  predicted_stage: "finetuning"
  estimated_switch_time: "2025-09-25 14:00:00"
  conditions:
    - "epoch >= 50"
    - "loss < 0.1"
```

## ğŸ“ é˜¶æ®µåŒ–æ•°æ®é›†é…ç½®æ ¼å¼

### é¢„è®­ç»ƒé˜¶æ®µé…ç½®ç¤ºä¾‹

**stages/pretraining.json**:
```json
{
    "meta": {
        "stage": "pretraining",
        "release_name": "Pretraining_Foundation_20250923",
        "consumer_version": "v1.2.0",
        "bundle_versions": ["v1.2.0-20250620-143500"],
        "created_at": "2025-09-23 10:30:00",
        "description": "é¢„è®­ç»ƒé˜¶æ®µåŸºç¡€æ•°æ®é›†",
        "version": "v1.2.0",
        "stage_config": {
            "data_ratio": {
                "highway": 0.4,
                "urban": 0.3,
                "parking": 0.2,
                "others": 0.1
            },
            "sampling_strategy": "balanced",
            "max_clips_per_dataset": 100000,
            "shuffle": true,
            "augmentation": {
                "enabled": true,
                "methods": ["rotation", "brightness", "noise"]
            }
        }
    },
    "dataset_index": [
        {
            "name": "highway_foundation_large",
            "obs_path": "obs://pretraining-data/highway_foundation_large.jsonl",
            "bundle_versions": ["v1.2.0-20250620-143500"],
            "duplicate": 10,
            "stage_weight": 0.4,
            "sampling_priority": "high",
            "enabled": true
        },
        {
            "name": "urban_scenarios_base",
            "obs_path": "obs://pretraining-data/urban_scenarios_base.jsonl", 
            "bundle_versions": ["v1.2.0-20250620-143500"],
            "duplicate": 8,
            "stage_weight": 0.3,
            "sampling_priority": "medium",
            "enabled": true
        }
    ]
}
```

### å¾®è°ƒé˜¶æ®µé…ç½®ç¤ºä¾‹

**stages/finetuning.json**:
```json
{
    "meta": {
        "stage": "finetuning",
        "release_name": "Finetuning_Specialized_20250923",
        "consumer_version": "v1.2.0", 
        "bundle_versions": ["v1.2.0-20250620-143500"],
        "created_at": "2025-09-23 10:30:00",
        "description": "å¾®è°ƒé˜¶æ®µç‰¹åŒ–æ•°æ®é›†",
        "version": "v1.2.0",
        "stage_config": {
            "data_ratio": {
                "toll_station": 0.6,
                "intersection": 0.3,
                "merge_lane": 0.1
            },
            "sampling_strategy": "targeted",
            "max_clips_per_dataset": 50000,
            "shuffle": false,
            "augmentation": {
                "enabled": false
            },
            "difficulty_progression": true
        }
    },
    "dataset_index": [
        {
            "name": "toll_station_scenarios_refined",
            "obs_path": "obs://finetuning-data/toll_station_scenarios_refined.jsonl",
            "bundle_versions": ["v1.2.0-20250620-143500"],
            "duplicate": 5,
            "stage_weight": 0.6,
            "sampling_priority": "critical",
            "enabled": true,
            "difficulty_level": "progressive"
        },
        {
            "name": "intersection_complex_cases",
            "obs_path": "obs://finetuning-data/intersection_complex_cases.jsonl",
            "bundle_versions": ["v1.2.0-20250620-143500"], 
            "duplicate": 3,
            "stage_weight": 0.3,
            "sampling_priority": "high",
            "enabled": true,
            "difficulty_level": "advanced"
        }
    ]
}
```

## ğŸ”§ å®ç°æœºåˆ¶

### 1. ç¯å¢ƒå˜é‡æ§åˆ¶

```bash
# è®¾ç½®è®­ç»ƒé˜¶æ®µ
export TRAINING_STAGE="finetuning"

# è®¾ç½®A/Bæµ‹è¯•å˜ä½“
export AB_VARIANT="variant_a"

# è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„
export STAGE_CONFIG_PATH="/path/to/data_release_repo/stage_config.yaml"

# å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šé…ç½®æ–‡ä»¶
export FORCE_DATASET_CONFIG="/path/to/custom_config.json"
```

### 2. æ•°æ®åŠ è½½é€»è¾‘

è®­ç»ƒä»£ç ä¸­çš„æ•°æ®åŠ è½½å™¨ä¼šæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§æŸ¥æ‰¾é…ç½®ï¼š

1. **ç¯å¢ƒå˜é‡æŒ‡å®šçš„é…ç½®æ–‡ä»¶** (`FORCE_DATASET_CONFIG`)
2. **å½“å‰æ¿€æ´»é˜¶æ®µçš„é…ç½®æ–‡ä»¶** (ä»`active_stage.yaml`è¯»å–)
3. **é»˜è®¤é…ç½®æ–‡ä»¶** (`training_dataset.json`)

### 3. é˜¶æ®µåˆ‡æ¢æœºåˆ¶

#### è‡ªåŠ¨åˆ‡æ¢
```python
# ä¼ªä»£ç ç¤ºä¾‹
def check_stage_switch_conditions():
    current_epoch = get_current_epoch()
    current_loss = get_current_loss()
    
    for stage, config in stage_configs.items():
        for condition in config.get('auto_switch_conditions', []):
            if evaluate_condition(condition, current_epoch, current_loss):
                switch_to_stage(stage)
                break
```

#### æ‰‹åŠ¨åˆ‡æ¢
```bash
# ä½¿ç”¨å·¥å…·è„šæœ¬åˆ‡æ¢é˜¶æ®µ
python scripts/stage_manager.py switch-stage finetuning

# æˆ–ç›´æ¥ä¿®æ”¹æ¿€æ´»æ–‡ä»¶
python scripts/stage_manager.py activate finetuning --reason "manual_switch"
```

## ğŸ› ï¸ é˜¶æ®µç®¡ç†å·¥å…·

### 1. é˜¶æ®µç®¡ç†å‘½ä»¤

```bash
# æŸ¥çœ‹å½“å‰é˜¶æ®µ
python scripts/stage_manager.py status

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨é˜¶æ®µ
python scripts/stage_manager.py list-stages

# åˆ‡æ¢åˆ°æŒ‡å®šé˜¶æ®µ
python scripts/stage_manager.py switch-stage finetuning

# é¢„è§ˆé˜¶æ®µé…ç½®
python scripts/stage_manager.py preview finetuning

# éªŒè¯é˜¶æ®µé…ç½®
python scripts/stage_manager.py validate-config stages/finetuning.json

# ç”Ÿæˆé˜¶æ®µæŠ¥å‘Š
python scripts/stage_manager.py report --output stage_report.md
```

### 2. é…ç½®ç”Ÿæˆå·¥å…·

```bash
# åŸºäºç°æœ‰é…ç½®ç”Ÿæˆé˜¶æ®µé…ç½®
python scripts/generate_stage_config.py \
  --base-config training_dataset.json \
  --stage pretraining \
  --ratio highway:0.4,urban:0.3,parking:0.3

# ä»æ¨¡æ¿åˆ›å»ºæ–°é˜¶æ®µ
python scripts/generate_stage_config.py \
  --template finetuning \
  --stage custom_experiment \
  --output stages/custom_experiment.json
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### 1. é˜¶æ®µåˆ‡æ¢æ—¥å¿—

```json
{
    "timestamp": "2025-09-23 14:30:00",
    "event": "stage_switch",
    "from_stage": "pretraining", 
    "to_stage": "finetuning",
    "trigger": "auto",
    "condition": "epoch >= 50",
    "metadata": {
        "epoch": 50,
        "loss": 0.08,
        "accuracy": 0.92
    }
}
```

### 2. æ•°æ®åŠ è½½ç»Ÿè®¡

```json
{
    "timestamp": "2025-09-23 14:30:00",
    "stage": "finetuning",
    "datasets_loaded": [
        {
            "name": "toll_station_scenarios_refined",
            "clips_loaded": 25000,
            "weight": 0.6,
            "load_time": "2.3s"
        }
    ],
    "total_clips": 41667,
    "total_load_time": "3.8s"
}
```

## ğŸ”„ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

### 1. å‘åå…¼å®¹

- å¦‚æœæ²¡æœ‰é˜¶æ®µé…ç½®ï¼Œè‡ªåŠ¨ä½¿ç”¨é»˜è®¤çš„`training_dataset.json`
- ç°æœ‰çš„è®­ç»ƒè„šæœ¬æ— éœ€ä¿®æ”¹ï¼Œé€šè¿‡ç¯å¢ƒå˜é‡é€æ˜åˆ‡æ¢
- ä¿æŒä¸DataSpecHubçš„ç‰ˆæœ¬è¿½æº¯å…³ç³»

### 2. ç‰ˆæœ¬ç®¡ç†

```bash
# ä¸ºç‰¹å®šé˜¶æ®µåˆ›å»ºTag
git tag -a "stage/pretraining/v1.2.0" -m "é¢„è®­ç»ƒé˜¶æ®µé…ç½® v1.2.0"

# ä¸ºé˜¶æ®µé…ç½®åˆ›å»ºåˆ†æ”¯
git checkout -b "feature_dataset/pretraining/optimization"
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯1: æ¸è¿›å¼è®­ç»ƒ
```bash
# è‡ªåŠ¨é˜¶æ®µåˆ‡æ¢è®­ç»ƒ
export TRAINING_STAGE="auto"
python train.py  # ä¼šè‡ªåŠ¨ä»pretraining -> finetuning -> evaluation
```

### åœºæ™¯2: A/Bæµ‹è¯•
```bash
# å¯åŠ¨A/Bæµ‹è¯•
export TRAINING_STAGE="ab_testing"
export AB_VARIANT="variant_a"  # æˆ–variant_b
python train.py
```

### åœºæ™¯3: ç‰¹å®šé˜¶æ®µè°ƒè¯•
```bash
# åªè¿è¡Œå¾®è°ƒé˜¶æ®µ
export TRAINING_STAGE="finetuning"
export FORCE_DATASET_CONFIG="stages/finetuning.json"
python train.py --debug
```

### åœºæ™¯4: åœ¨çº¿å­¦ä¹ 
```bash
# åˆ‡æ¢åˆ°åœ¨çº¿å­¦ä¹ æ¨¡å¼
python scripts/stage_manager.py switch-stage online_learning
python online_training.py
```

## ğŸ“‹ é…ç½®æ–‡ä»¶æ¨¡æ¿

è¯¦è§ï¼š
- [pretraining_template.json](templates/pretraining_template.json)
- [finetuning_template.json](templates/finetuning_template.json) 
- [evaluation_template.json](templates/evaluation_template.json)
- [ab_testing_template.json](templates/ab_testing_template.json)

## ğŸš€ éƒ¨ç½²å»ºè®®

### 1. å¼€å‘ç¯å¢ƒ
```bash
# ä½¿ç”¨æœ¬åœ°é…ç½®
export STAGE_CONFIG_PATH="./stage_config.yaml"
export TRAINING_STAGE="finetuning"
```

### 2. ç”Ÿäº§ç¯å¢ƒ
```bash
# ä½¿ç”¨è¿œç¨‹é…ç½®
export STAGE_CONFIG_PATH="obs://config-bucket/stage_config.yaml"
export TRAINING_STAGE="auto"
```

### 3. å®¹å™¨åŒ–éƒ¨ç½²
```dockerfile
# åœ¨Dockerfileä¸­è®¾ç½®
ENV STAGE_CONFIG_PATH=/app/config/stage_config.yaml
ENV TRAINING_STAGE=pretraining
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®ä¸€è‡´æ€§**: åˆ‡æ¢é˜¶æ®µæ—¶ç¡®ä¿æ•°æ®é›†çš„ç‰ˆæœ¬ä¸€è‡´æ€§
2. **ç¼“å­˜æ¸…ç†**: é˜¶æ®µåˆ‡æ¢åå¯èƒ½éœ€è¦æ¸…ç†æ•°æ®åŠ è½½ç¼“å­˜
3. **èµ„æºç®¡ç†**: ä¸åŒé˜¶æ®µå¯èƒ½éœ€è¦ä¸åŒçš„è®¡ç®—èµ„æºé…ç½®
4. **ç›‘æ§æŠ¥è­¦**: è®¾ç½®é˜¶æ®µåˆ‡æ¢çš„ç›‘æ§å’ŒæŠ¥è­¦æœºåˆ¶
5. **å›æ»šæœºåˆ¶**: æä¾›å¿«é€Ÿå›æ»šåˆ°ä¸Šä¸€é˜¶æ®µçš„èƒ½åŠ›

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- [é˜¶æ®µç®¡ç†å·¥å…·ä½¿ç”¨æŒ‡å—](stage_manager_guide.md)
- [é…ç½®æ–‡ä»¶æ ¼å¼è§„èŒƒ](stage_config_format.md)
- [æ•…éšœæ’é™¤æŒ‡å—](troubleshooting.md)

---

**ç»´æŠ¤å›¢é˜Ÿ**: Data Platform Team  
**æœ€åæ›´æ–°**: 2025-09-23

