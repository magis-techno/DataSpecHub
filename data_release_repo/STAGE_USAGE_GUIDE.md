# é˜¶æ®µåŒ–æ•°æ®åŠ è½½ä½¿ç”¨æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå˜é‡æ–¹å¼ï¼ˆæ¨èï¼‰

è¿™æ˜¯æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼ï¼Œæ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç ï¼š

```bash
# è®¾ç½®è®­ç»ƒé˜¶æ®µ
export TRAINING_STAGE="finetuning"

# è¿è¡Œè®­ç»ƒï¼ˆä½ çš„ç°æœ‰ä»£ç ï¼‰
python train.py
```

ä½ çš„è®­ç»ƒä»£ç ä¼šè‡ªåŠ¨åŠ è½½å¯¹åº”é˜¶æ®µçš„æ•°æ®é…ç½®ã€‚

### 2. æ‰‹åŠ¨åˆ‡æ¢é˜¶æ®µ

```bash
# åˆ‡æ¢åˆ°å¾®è°ƒé˜¶æ®µ
python scripts/stage_manager.py switch-stage finetuning

# åˆ‡æ¢åˆ°è¯„ä¼°é˜¶æ®µ
python scripts/stage_manager.py switch-stage evaluation

# A/Bæµ‹è¯•ï¼ˆåˆ‡æ¢åˆ°å˜ä½“Aï¼‰
python scripts/stage_manager.py switch-stage ab_testing --variant variant_a
```

### 3. æŸ¥çœ‹å½“å‰çŠ¶æ€

```bash
# æŸ¥çœ‹å½“å‰é˜¶æ®µ
python scripts/stage_manager.py status

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨é˜¶æ®µ
python scripts/stage_manager.py list-stages
```

## ğŸ”§ é›†æˆåˆ°ç°æœ‰ä»£ç 

### æ–¹æ³•1: ç¯å¢ƒå˜é‡æ£€æµ‹ï¼ˆæ¨èï¼‰

åœ¨ä½ çš„æ•°æ®åŠ è½½ä»£ç ä¸­æ·»åŠ ä»¥ä¸‹é€»è¾‘ï¼š

```python
import os
import json
import yaml

def get_dataset_config():
    """è·å–æ•°æ®é›†é…ç½®ï¼Œæ”¯æŒé˜¶æ®µåŒ–åŠ è½½"""
    
    # 1. æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶æŒ‡å®šé…ç½®æ–‡ä»¶
    force_config = os.getenv('FORCE_DATASET_CONFIG')
    if force_config and os.path.exists(force_config):
        with open(force_config, 'r') as f:
            return json.load(f)
    
    # 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„é˜¶æ®µ
    active_stage_file = 'active_stage.yaml'
    if os.path.exists(active_stage_file):
        with open(active_stage_file, 'r') as f:
            active_stage = yaml.safe_load(f)
        
        config_file = active_stage.get('config_file')
        if config_file and os.path.exists(config_file):
            with open(config_file, 'r') as f:
                return json.load(f)
    
    # 3. ä½¿ç”¨é»˜è®¤é…ç½®
    default_config = 'training_dataset.json'
    if os.path.exists(default_config):
        with open(default_config, 'r') as f:
            return json.load(f)
    
    raise FileNotFoundError("æœªæ‰¾åˆ°æ•°æ®é›†é…ç½®æ–‡ä»¶")

# åœ¨ä½ çš„è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨
config = get_dataset_config()
dataset_index = config['dataset_index']

# æŒ‰é˜¶æ®µé…ç½®åˆ›å»ºæ•°æ®åŠ è½½å™¨
stage_config = config['meta'].get('stage_config', {})
batch_size = stage_config.get('loading_config', {}).get('batch_size', 32)
```

### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨é˜¶æ®µç®¡ç†å™¨

```python
from scripts.stage_manager import StageManager

def create_data_loader():
    """åˆ›å»ºåŸºäºå½“å‰é˜¶æ®µçš„æ•°æ®åŠ è½½å™¨"""
    manager = StageManager()
    
    # è·å–å½“å‰é˜¶æ®µé…ç½®
    current_stage, variant = manager.get_current_stage()
    config = manager.preview_stage_config(current_stage, variant)
    
    # æ ¹æ®é…ç½®åˆ›å»ºæ•°æ®åŠ è½½å™¨
    batch_size = config.get('stage_config', {}).get('loading_config', {}).get('batch_size', 32)
    
    # ä½ çš„æ•°æ®åŠ è½½é€»è¾‘
    return create_dataloader_with_config(config, batch_size)
```

## ğŸ“Š å®é™…ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: æ¸è¿›å¼è®­ç»ƒ

```bash
# å¯åŠ¨è‡ªåŠ¨é˜¶æ®µåˆ‡æ¢è®­ç»ƒ
export TRAINING_STAGE="auto"
python train.py

# è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨ç»å†ï¼š
# pretraining (0-50 epochs) â†’ finetuning (50-100 epochs) â†’ evaluation
```

### åœºæ™¯2: ç‰¹å®šé˜¶æ®µè°ƒè¯•

```bash
# åªæµ‹è¯•å¾®è°ƒé˜¶æ®µçš„æ•°æ®
export TRAINING_STAGE="finetuning"
python train.py --epochs 5 --debug

# æˆ–è€…ä½¿ç”¨ç‰¹å®šé…ç½®æ–‡ä»¶
export FORCE_DATASET_CONFIG="stages/finetuning.json"
python train.py --debug
```

### åœºæ™¯3: A/Bæµ‹è¯•

```bash
# å¯åŠ¨Aç»„å®éªŒ
export TRAINING_STAGE="ab_testing"
export AB_VARIANT="variant_a"
python train.py --experiment-name "exp_a"

# å¯åŠ¨Bç»„å®éªŒï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
export AB_VARIANT="variant_b"  
python train.py --experiment-name "exp_b"
```

### åœºæ™¯4: åœ¨çº¿å­¦ä¹ 

```bash
# åˆ‡æ¢åˆ°åœ¨çº¿å­¦ä¹ æ¨¡å¼
python scripts/stage_manager.py switch-stage online_learning

# å¯åŠ¨åœ¨çº¿è®­ç»ƒ
python online_training.py
```

## ğŸ› ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰é˜¶æ®µé…ç½®

ä½ å¯ä»¥åˆ›å»ºè‡ªå·±çš„é˜¶æ®µé…ç½®ï¼š

```bash
# å¤åˆ¶ç°æœ‰é…ç½®ä½œä¸ºæ¨¡æ¿
cp stages/finetuning.json stages/my_custom_stage.json

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim stages/my_custom_stage.json

# åœ¨stage_config.yamlä¸­æ·»åŠ æ–°é˜¶æ®µ
vim stage_config.yaml
```

### æ¡ä»¶åˆ‡æ¢

åœ¨`stage_config.yaml`ä¸­é…ç½®è‡ªåŠ¨åˆ‡æ¢æ¡ä»¶ï¼š

```yaml
stages:
  my_custom_stage:
    name: "è‡ªå®šä¹‰é˜¶æ®µ"
    config_file: "stages/my_custom_stage.json"
    auto_switch_conditions:
      - epoch: 75
        condition: "custom_trigger"
      - metric: "accuracy"
        threshold: 0.9
        operator: ">"
```

### ç¯å¢ƒç‰¹å®šé…ç½®

```yaml
environments:
  development:
    switch_strategy:
      mode: "manual"  # å¼€å‘ç¯å¢ƒæ‰‹åŠ¨åˆ‡æ¢
  
  production:
    switch_strategy:
      mode: "auto"    # ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åˆ‡æ¢
      check_interval: 10
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹é˜¶æ®µåˆ‡æ¢å†å²

```bash
# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
python scripts/stage_manager.py report --output stage_report.md

# æŸ¥çœ‹åˆ‡æ¢å†å²
python scripts/stage_manager.py status
```

### å®æ—¶ç›‘æ§

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ ç›‘æ§
def training_loop():
    manager = StageManager()
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé€»è¾‘
        train_epoch()
        
        # æ›´æ–°æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
        current_metrics = {
            'epoch': epoch,
            'loss': current_loss,
            'accuracy': current_accuracy
        }
        # è¿™é‡Œå¯ä»¥æ·»åŠ æŒ‡æ ‡æ›´æ–°é€»è¾‘
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢é˜¶æ®µ
        if should_check_stage_switch(epoch):
            status = manager.get_stage_status()
            print(f"å½“å‰é˜¶æ®µ: {status['current_stage']}")
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### Q: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la stages/
python scripts/stage_manager.py list-stages
```

#### Q: é˜¶æ®µåˆ‡æ¢ä¸ç”Ÿæ•ˆ
```bash
# éªŒè¯é…ç½®
python scripts/stage_manager.py validate-config finetuning

# æ£€æŸ¥å½“å‰çŠ¶æ€
python scripts/stage_manager.py status
```

#### Q: ç¯å¢ƒå˜é‡ä¸ç”Ÿæ•ˆ
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $TRAINING_STAGE
echo $FORCE_DATASET_CONFIG

# é‡æ–°è®¾ç½®
export TRAINING_STAGE="finetuning"
```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è°ƒè¯•æ—¥å¿—
export STAGE_DEBUG=1
python scripts/stage_manager.py status

# é¢„è§ˆé…ç½®è€Œä¸åˆ‡æ¢
python scripts/stage_manager.py preview finetuning
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç‰ˆæœ¬æ§åˆ¶

```bash
# ä¸ºé˜¶æ®µé…ç½®åˆ›å»ºç‰ˆæœ¬Tag
git add stages/
git commit -m "æ›´æ–°å¾®è°ƒé˜¶æ®µé…ç½®

date: \"2025-09-23\"
type: \"modify(balance)\"
description: \"ä¼˜åŒ–å¾®è°ƒé˜¶æ®µæ•°æ®æ¯”ä¾‹\"
details:
  stage: \"finetuning\"
  toll_station_ratio: 0.6
  intersection_ratio: 0.3"

git tag -a "stage/finetuning/v1.2.1" -m "å¾®è°ƒé˜¶æ®µé…ç½® v1.2.1"
```

### 2. ç¯å¢ƒéš”ç¦»

```bash
# å¼€å‘ç¯å¢ƒ
export STAGE_CONFIG_PATH="./dev_stage_config.yaml"
export TRAINING_STAGE="finetuning"

# ç”Ÿäº§ç¯å¢ƒ
export STAGE_CONFIG_PATH="/app/config/prod_stage_config.yaml"
export TRAINING_STAGE="auto"
```

### 3. å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.9

# å¤åˆ¶é˜¶æ®µé…ç½®
COPY data_release_repo/ /app/data_release_repo/
COPY scripts/ /app/scripts/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV STAGE_CONFIG_PATH=/app/data_release_repo/stage_config.yaml
ENV TRAINING_STAGE=pretraining

# å¯åŠ¨è„šæœ¬
CMD ["python", "train.py"]
```

### 4. CI/CDé›†æˆ

```yaml
# .github/workflows/training.yml
name: Training Pipeline

on:
  push:
    branches: [main]

jobs:
  pretraining:
    runs-on: ubuntu-latest
    env:
      TRAINING_STAGE: pretraining
    steps:
      - uses: actions/checkout@v3
      - name: Run pretraining
        run: python train.py --epochs 50

  finetuning:
    needs: pretraining
    runs-on: ubuntu-latest
    env:
      TRAINING_STAGE: finetuning
    steps:
      - uses: actions/checkout@v3
      - name: Run finetuning
        run: python train.py --epochs 30
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [é˜¶æ®µåŒ–æ•°æ®åŠ è½½æœºåˆ¶è¯¦è§£](docs/Stage_Based_Data_Loading.md)
- [è®­ç»ƒæ•°æ®é›†ç®¡ç†Wiki](docs/Training_Dataset_Management_Wiki.md)
- [Gitåˆ†æ”¯ç­–ç•¥](docs/Git_Branch_Strategy.md)

## ğŸ“ æŠ€æœ¯æ”¯æŒ

é‡åˆ°é—®é¢˜æ—¶çš„æ’æŸ¥æ­¥éª¤ï¼š

1. **æ£€æŸ¥é…ç½®**: `python scripts/stage_manager.py validate-config <stage>`
2. **æŸ¥çœ‹çŠ¶æ€**: `python scripts/stage_manager.py status`
3. **ç”ŸæˆæŠ¥å‘Š**: `python scripts/stage_manager.py report`
4. **æ£€æŸ¥æ—¥å¿—**: æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ä¸­çš„æ•°æ®åŠ è½½ä¿¡æ¯
5. **è”ç³»æ”¯æŒ**: æä¾›æŠ¥å‘Šå’Œé”™è¯¯ä¿¡æ¯

---

**ç»´æŠ¤å›¢é˜Ÿ**: Data Platform Team  
**æœ€åæ›´æ–°**: 2025-09-23

