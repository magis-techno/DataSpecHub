#!/usr/bin/env python3
"""
é˜¶æ®µåŒ–æ•°æ®åŠ è½½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•åœ¨ä¸ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹åˆ‡æ¢ä¸åŒé˜¶æ®µçš„æ•°æ®
"""

import os
import json
import yaml
from pathlib import Path

def get_dataset_config():
    """è·å–æ•°æ®é›†é…ç½®ï¼Œæ”¯æŒé˜¶æ®µåŒ–åŠ è½½"""
    
    print("ğŸ” æ­£åœ¨æ£€æµ‹æ•°æ®é›†é…ç½®...")
    
    # 1. æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶æŒ‡å®šé…ç½®æ–‡ä»¶
    force_config = os.getenv('FORCE_DATASET_CONFIG')
    if force_config and os.path.exists(force_config):
        print(f"âœ… ä½¿ç”¨å¼ºåˆ¶æŒ‡å®šçš„é…ç½®æ–‡ä»¶: {force_config}")
        with open(force_config, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    # 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„é˜¶æ®µ
    active_stage_file = 'active_stage.yaml'
    if os.path.exists(active_stage_file):
        print(f"ğŸ“„ è¯»å–æ¿€æ´»é˜¶æ®µæ–‡ä»¶: {active_stage_file}")
        with open(active_stage_file, 'r', encoding='utf-8') as f:
            active_stage = yaml.safe_load(f)
        
        current_stage = active_stage.get('current_stage')
        config_file = active_stage.get('config_file')
        
        print(f"ğŸ“Š å½“å‰æ¿€æ´»é˜¶æ®µ: {current_stage}")
        
        if config_file and os.path.exists(config_file):
            print(f"âœ… ä½¿ç”¨é˜¶æ®µé…ç½®æ–‡ä»¶: {config_file}")
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
    
    # 3. æ£€æŸ¥ç¯å¢ƒå˜é‡æŒ‡å®šçš„é˜¶æ®µ
    env_stage = os.getenv('TRAINING_STAGE')
    if env_stage:
        print(f"ğŸŒ ç¯å¢ƒå˜é‡æŒ‡å®šé˜¶æ®µ: {env_stage}")
        stage_file = f"stages/{env_stage}.json"
        if os.path.exists(stage_file):
            print(f"âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡é˜¶æ®µé…ç½®: {stage_file}")
            with open(stage_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print(f"âš ï¸  ç¯å¢ƒå˜é‡é˜¶æ®µé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {stage_file}")
    
    # 4. ä½¿ç”¨é»˜è®¤é…ç½®
    default_configs = ['training_dataset.json', '../training_dataset.json']
    for default_config in default_configs:
        if os.path.exists(default_config):
            print(f"âœ… ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶: {default_config}")
            with open(default_config, 'r', encoding='utf-8') as f:
                return json.load(f)
    
    print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®é›†é…ç½®æ–‡ä»¶")
    return None

def analyze_config(config):
    """åˆ†æé…ç½®æ–‡ä»¶å†…å®¹"""
    if not config:
        return
    
    print("\nğŸ“‹ é…ç½®åˆ†æ:")
    print("=" * 50)
    
    meta = config.get('meta', {})
    stage = meta.get('stage', 'unknown')
    description = meta.get('description', 'æ— æè¿°')
    
    print(f"é˜¶æ®µåç§°: {stage}")
    print(f"æè¿°: {description}")
    print(f"ç‰ˆæœ¬: {meta.get('version', 'N/A')}")
    print(f"Consumerç‰ˆæœ¬: {meta.get('consumer_version', 'N/A')}")
    
    # æ•°æ®é›†ç»Ÿè®¡
    dataset_index = config.get('dataset_index', [])
    total_datasets = len(dataset_index)
    total_clips = sum(ds.get('duplicate', 1) for ds in dataset_index)
    
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"æ•°æ®é›†æ•°é‡: {total_datasets}")
    print(f"æ€»Clipsæ•°é‡: {total_clips:,}")
    
    # é˜¶æ®µç‰¹å®šé…ç½®
    stage_config = meta.get('stage_config', {})
    if stage_config:
        print(f"\nâš™ï¸  é˜¶æ®µé…ç½®:")
        
        data_strategy = stage_config.get('data_strategy', {})
        if data_strategy:
            print(f"é‡‡æ ·æ–¹æ³•: {data_strategy.get('sampling_method', 'N/A')}")
            
            data_ratio = data_strategy.get('data_ratio', {})
            if data_ratio:
                print("æ•°æ®æ¯”ä¾‹:")
                for scenario, ratio in data_ratio.items():
                    print(f"  - {scenario}: {ratio:.1%}")
        
        loading_config = stage_config.get('loading_config', {})
        if loading_config:
            print(f"æ‰¹æ¬¡å¤§å°: {loading_config.get('batch_size', 'N/A')}")
            print(f"å·¥ä½œçº¿ç¨‹: {loading_config.get('num_workers', 'N/A')}")
    
    # æ•°æ®é›†è¯¦æƒ…
    print(f"\nğŸ“ æ•°æ®é›†åˆ—è¡¨:")
    for i, dataset in enumerate(dataset_index, 1):
        name = dataset.get('name', f'dataset_{i}')
        clips = dataset.get('duplicate', 1)
        weight = dataset.get('stage_weight', 0)
        enabled = dataset.get('enabled', True)
        status = "âœ…" if enabled else "âŒ"
        
        print(f"  {status} {name}")
        print(f"     Clips: {clips:,} | æƒé‡: {weight} | å¯ç”¨: {enabled}")

def demo_stage_switching():
    """æ¼”ç¤ºé˜¶æ®µåˆ‡æ¢"""
    print("\nğŸ¯ é˜¶æ®µåˆ‡æ¢æ¼”ç¤º")
    print("=" * 50)
    
    stages = ['pretraining', 'finetuning', 'evaluation']
    
    for stage in stages:
        print(f"\nğŸ”„ åˆ‡æ¢åˆ°é˜¶æ®µ: {stage}")
        print("-" * 30)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['TRAINING_STAGE'] = stage
        
        # è·å–é…ç½®
        config = get_dataset_config()
        if config:
            meta = config.get('meta', {})
            dataset_count = len(config.get('dataset_index', []))
            total_clips = sum(ds.get('duplicate', 1) for ds in config.get('dataset_index', []))
            
            print(f"âœ… æˆåŠŸåŠ è½½ {stage} é˜¶æ®µé…ç½®")
            print(f"   æ•°æ®é›†: {dataset_count}ä¸ª")
            print(f"   Clips: {total_clips:,}ä¸ª")
            
            # æ˜¾ç¤ºé˜¶æ®µç‰¹å®šé…ç½®
            stage_config = meta.get('stage_config', {})
            if stage_config:
                loading_config = stage_config.get('loading_config', {})
                batch_size = loading_config.get('batch_size', 'N/A')
                print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        else:
            print(f"âŒ æ— æ³•åŠ è½½ {stage} é˜¶æ®µé…ç½®")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é˜¶æ®µåŒ–æ•°æ®åŠ è½½æ¼”ç¤º")
    print("=" * 60)
    
    # æ˜¾ç¤ºå½“å‰ç¯å¢ƒ
    print("ğŸŒ å½“å‰ç¯å¢ƒå˜é‡:")
    env_vars = ['TRAINING_STAGE', 'AB_VARIANT', 'FORCE_DATASET_CONFIG']
    for var in env_vars:
        value = os.getenv(var, 'æœªè®¾ç½®')
        print(f"   {var}: {value}")
    
    print(f"\nğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ“ å¯ç”¨æ–‡ä»¶:")
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    files_to_check = [
        'stage_config.yaml',
        'active_stage.yaml',
        'stages/pretraining.json',
        'stages/finetuning.json',
        'stages/evaluation.json'
    ]
    
    for file_path in files_to_check:
        exists = "âœ…" if os.path.exists(file_path) else "âŒ"
        print(f"   {exists} {file_path}")
    
    # è·å–å¹¶åˆ†æå½“å‰é…ç½®
    print(f"\nğŸ“– å½“å‰é…ç½®åˆ†æ:")
    config = get_dataset_config()
    analyze_config(config)
    
    # æ¼”ç¤ºé˜¶æ®µåˆ‡æ¢
    if any(os.path.exists(f"stages/{stage}.json") for stage in ['pretraining', 'finetuning', 'evaluation']):
        demo_stage_switching()
    
    print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. è®¾ç½®ç¯å¢ƒå˜é‡åˆ‡æ¢é˜¶æ®µ:")
    print("   export TRAINING_STAGE=finetuning")
    print("   python demo_stage_usage.py")
    print()
    print("2. ä½¿ç”¨é˜¶æ®µç®¡ç†å·¥å…·:")
    print("   python scripts/stage_manager.py switch-stage finetuning")
    print("   python scripts/stage_manager.py status")
    print()
    print("3. å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šé…ç½®:")
    print("   export FORCE_DATASET_CONFIG=stages/evaluation.json")
    print("   python demo_stage_usage.py")

if __name__ == "__main__":
    main()

