#!/usr/bin/env python3
"""
Tagå’ŒReleaseåˆ›å»ºè¾…åŠ©å·¥å…·
"""

import os
import sys
import argparse
import subprocess
import json
import yaml
from datetime import datetime
from typing import Dict, Optional, List, Any

class TagReleaseHelper:
    def __init__(self):
        self.repo_root = self._get_repo_root()
        
    def _get_repo_root(self) -> str:
        """è·å–Gitä»“åº“æ ¹ç›®å½•"""
        try:
            result = subprocess.run(
                ['git', 'rev-parse', '--show-toplevel'],
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError:
            print("âŒ å½“å‰ç›®å½•ä¸æ˜¯Gitä»“åº“")
            sys.exit(1)
    
    def _run_git_command(self, cmd: List[str]) -> str:
        """æ‰§è¡ŒGitå‘½ä»¤"""
        try:
            result = subprocess.run(
                ['git'] + cmd,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            print(f"âŒ Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {' '.join(cmd)}")
            print(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
            return ""
    
    def get_dataset_info(self) -> Optional[Dict[str, Any]]:
        """ä»training_dataset.jsonè·å–æ•°æ®é›†ä¿¡æ¯"""
        dataset_files = ['training_dataset.json', 'training_dataset.dagger.json']
        
        for filename in dataset_files:
            if os.path.exists(filename):
                try:
                    with open(filename, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    return data
                except json.JSONDecodeError:
                    continue
        
        return None
    
    def create_feature_tag(self, topic: str, date: str = None) -> bool:
        """åˆ›å»ºä¸“é¢˜æ•°æ®äº¤ä»˜Tag"""
        if not date:
            date = datetime.now().strftime("%Y%m%d")
        
        tag_name = f"feature_dataset/{topic}/release-{date}"
        
        print(f"ğŸ·ï¸  åˆ›å»ºä¸“é¢˜æ•°æ®äº¤ä»˜Tag: {tag_name}")
        
        # æ£€æŸ¥Tagæ˜¯å¦å·²å­˜åœ¨
        existing_tags = self._run_git_command(['tag', '-l'])
        if tag_name in existing_tags.split('\n'):
            print(f"âŒ Tag {tag_name} å·²å­˜åœ¨")
            return False
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        dataset_info = self.get_dataset_info()
        if not dataset_info:
            print("âš ï¸  æœªæ‰¾åˆ°training_dataset.jsonï¼Œå°†åˆ›å»ºç®€å•çš„Tagæ³¨é‡Š")
            tag_annotation = f"ä¸“é¢˜æ•°æ®äº¤ä»˜: {topic}"
        else:
            meta = dataset_info.get('meta', {})
            dataset_index = dataset_info.get('dataset_index', [])
            
            # åˆ›å»ºTagæ³¨é‡Š
            tag_annotation_dict = {
                'release_name': tag_name,
                'consumer_version': meta.get('consumer_version', ''),
                'bundle_version': meta.get('bundle_versions', [''])[0],
                'training_dataset_version': meta.get('version', ''),
                'description': f"{topic}åœºæ™¯æ•°æ®é›†ä¸“é¢˜äº¤ä»˜",
                'datasets_count': len(dataset_index),
                'total_clips': sum(ds.get('duplicate', 1) for ds in dataset_index),
                'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            tag_annotation = yaml.dump(tag_annotation_dict, default_flow_style=False, allow_unicode=True)
        
        # åˆ›å»ºå¸¦æ³¨é‡Šçš„Tag
        try:
            subprocess.run(['git', 'tag', '-a', tag_name, '-m', tag_annotation], check=True)
            print(f"âœ… æˆåŠŸåˆ›å»ºTag: {tag_name}")
            
            # è¯¢é—®æ˜¯å¦æ¨é€
            push = input("ğŸš€ æ˜¯å¦æ¨é€Tagåˆ°è¿œç¨‹ä»“åº“? (y/N): ").strip().lower()
            if push == 'y':
                subprocess.run(['git', 'push', 'origin', tag_name], check=True)
                print("âœ… Tagå·²æ¨é€åˆ°è¿œç¨‹ä»“åº“")
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ åˆ›å»ºTagå¤±è´¥: {e}")
            return False
    
    def create_version_tag(self, version: str) -> bool:
        """åˆ›å»ºå¤§ç‰ˆæœ¬Tag"""
        if not version.startswith('v'):
            version = f"v{version}"
        
        tag_name = f"training/{version}"
        
        print(f"ğŸ·ï¸  åˆ›å»ºç‰ˆæœ¬Tag: {tag_name}")
        
        # æ£€æŸ¥Tagæ˜¯å¦å·²å­˜åœ¨
        existing_tags = self._run_git_command(['tag', '-l'])
        if tag_name in existing_tags.split('\n'):
            print(f"âŒ Tag {tag_name} å·²å­˜åœ¨")
            return False
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        dataset_info = self.get_dataset_info()
        if not dataset_info:
            print("âŒ åˆ›å»ºç‰ˆæœ¬Tagéœ€è¦training_dataset.jsonæ–‡ä»¶")
            return False
        
        meta = dataset_info.get('meta', {})
        dataset_index = dataset_info.get('dataset_index', [])
        
        # éªŒè¯ç‰ˆæœ¬ä¸€è‡´æ€§
        dataset_version = meta.get('version', '')
        if dataset_version != version:
            print(f"âš ï¸  training_dataset.jsonä¸­çš„ç‰ˆæœ¬({dataset_version})ä¸Tagç‰ˆæœ¬({version})ä¸ä¸€è‡´")
            confirm = input("æ˜¯å¦ç»§ç»­åˆ›å»ºTag? (y/N): ").strip().lower()
            if confirm != 'y':
                return False
        
        # åˆ›å»ºTagæ³¨é‡Š
        tag_annotation_dict = {
            'release_name': f"TrainingDataset {version}",
            'consumer_version': meta.get('consumer_version', ''),
            'bundle_versions': meta.get('bundle_versions', []),
            'training_dataset_version': version,
            'description': f"è®­ç»ƒæ•°æ®é›† {version} ç‰ˆæœ¬å‘å¸ƒ",
            'datasets_count': len(dataset_index),
            'total_clips': sum(ds.get('duplicate', 1) for ds in dataset_index),
            'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'release_type': 'major'
        }
        
        tag_annotation = yaml.dump(tag_annotation_dict, default_flow_style=False, allow_unicode=True)
        
        # åˆ›å»ºå¸¦æ³¨é‡Šçš„Tag
        try:
            subprocess.run(['git', 'tag', '-a', tag_name, '-m', tag_annotation], check=True)
            print(f"âœ… æˆåŠŸåˆ›å»ºç‰ˆæœ¬Tag: {tag_name}")
            
            # è¯¢é—®æ˜¯å¦æ¨é€
            push = input("ğŸš€ æ˜¯å¦æ¨é€Tagåˆ°è¿œç¨‹ä»“åº“? (y/N): ").strip().lower()
            if push == 'y':
                subprocess.run(['git', 'push', 'origin', tag_name], check=True)
                print("âœ… Tagå·²æ¨é€åˆ°è¿œç¨‹ä»“åº“")
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ åˆ›å»ºTagå¤±è´¥: {e}")
            return False
    
    def generate_release_notes(self, version: str, previous_version: str = None) -> str:
        """ç”ŸæˆReleaseè¯´æ˜"""
        dataset_info = self.get_dataset_info()
        
        if not dataset_info:
            return f"# TrainingDataset {version}\n\nå‘å¸ƒè¯´æ˜å¾…å®Œå–„..."
        
        meta = dataset_info.get('meta', {})
        dataset_index = dataset_info.get('dataset_index', [])
        
        # åŸºæœ¬ä¿¡æ¯
        release_notes = f"# TrainingDataset {version}\n\n"
        release_notes += "## ç‰ˆæœ¬ä¿¡æ¯\n"
        release_notes += f"- **Consumer Version**: {meta.get('consumer_version', 'N/A')}\n"
        release_notes += f"- **Bundle Versions**: {', '.join(meta.get('bundle_versions', []))}\n"
        release_notes += f"- **å‘å¸ƒæ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}\n\n"
        
        # æ•°æ®ç»Ÿè®¡
        release_notes += "## æ•°æ®ç»Ÿè®¡\n"
        release_notes += f"- **æ€»æ•°æ®é›†æ•°é‡**: {len(dataset_index)}ä¸ª\n"
        release_notes += f"- **æ€»Clipsæ•°é‡**: {sum(ds.get('duplicate', 1) for ds in dataset_index):,}\n"
        
        # è®­ç»ƒç±»å‹ç»Ÿè®¡
        training_type = meta.get('training_type', 'regular')
        if training_type == 'dagger':
            release_notes += "- **æ”¯æŒè®­ç»ƒç±»å‹**: DAggerè®­ç»ƒ\n"
        else:
            release_notes += "- **æ”¯æŒè®­ç»ƒç±»å‹**: å¸¸è§„è®­ç»ƒ\n"
        
        release_notes += "\n## æ•°æ®é›†åˆ—è¡¨\n"
        for i, dataset in enumerate(dataset_index, 1):
            dataset_name = dataset.get('name', f'dataset_{i}')
            clips_count = dataset.get('duplicate', 1)
            bundle_versions = dataset.get('bundle_versions', [])
            release_notes += f"{i}. **{dataset_name}** - {clips_count:,} clips\n"
            release_notes += f"   - Bundleç‰ˆæœ¬: {', '.join(bundle_versions)}\n"
        
        # å˜æ›´æ—¥å¿— (éœ€è¦æ‰‹åŠ¨è¡¥å……)
        release_notes += "\n## ä¸»è¦å˜æ›´\n"
        release_notes += "### æ–°å¢åŠŸèƒ½\n"
        release_notes += "- TODO: è¯·è¡¥å……æ–°å¢åŠŸèƒ½\n\n"
        release_notes += "### æ•°æ®ä¼˜åŒ–\n"
        release_notes += "- TODO: è¯·è¡¥å……æ•°æ®ä¼˜åŒ–å†…å®¹\n\n"
        release_notes += "### Bugä¿®å¤\n"
        release_notes += "- TODO: è¯·è¡¥å……Bugä¿®å¤å†…å®¹\n\n"
        
        # å…¼å®¹æ€§ä¿¡æ¯
        release_notes += "## å…¼å®¹æ€§\n"
        consumer_version = meta.get('consumer_version', '')
        if consumer_version:
            major_minor = '.'.join(consumer_version.split('.')[:2])
            release_notes += f"- å‘ä¸‹å…¼å®¹ {major_minor}.x\n"
            release_notes += f"- éœ€è¦DataSpecHub {consumer_version}+æ”¯æŒ\n\n"
        
        # è·å–å˜æ›´å†å² (å¦‚æœæœ‰ä¸Šä¸€ä¸ªç‰ˆæœ¬)
        if previous_version:
            try:
                previous_tag = f"training/{previous_version}"
                current_commit = self._run_git_command(['rev-parse', 'HEAD'])
                commits = self._run_git_command(['log', '--oneline', f'{previous_tag}..{current_commit}'])
                
                if commits:
                    release_notes += "## æäº¤å†å²\n"
                    for commit in commits.split('\n'):
                        if commit.strip():
                            release_notes += f"- {commit}\n"
                    release_notes += "\n"
            except:
                pass
        
        release_notes += "## è¿ç§»æŒ‡å—\n"
        release_notes += "è¯¦è§: [Migration_Guide.md](docs/migrations/Migration_Guide.md)\n"
        
        return release_notes
    
    def create_release_draft(self, version: str, previous_version: str = None) -> bool:
        """åˆ›å»ºReleaseè‰ç¨¿"""
        if not version.startswith('v'):
            version = f"v{version}"
        
        tag_name = f"training/{version}"
        
        # æ£€æŸ¥Tagæ˜¯å¦å­˜åœ¨
        existing_tags = self._run_git_command(['tag', '-l'])
        if tag_name not in existing_tags.split('\n'):
            print(f"âŒ Tag {tag_name} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºTag")
            return False
        
        # ç”ŸæˆReleaseè¯´æ˜
        release_notes = self.generate_release_notes(version, previous_version)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        release_file = f"release_notes_{version.replace('v', '')}.md"
        with open(release_file, 'w', encoding='utf-8') as f:
            f.write(release_notes)
        
        print(f"ğŸ“ Releaseè¯´æ˜å·²ç”Ÿæˆ: {release_file}")
        print("ğŸ’¡ è¯·ç¼–è¾‘æ­¤æ–‡ä»¶å®Œå–„å‘å¸ƒè¯´æ˜ï¼Œç„¶ååœ¨GitHubä¸Šåˆ›å»ºRelease")
        print(f"   Tag: {tag_name}")
        print(f"   Title: TrainingDataset {version}")
        
        return True

def main():
    parser = argparse.ArgumentParser(description='Tagå’ŒReleaseåˆ›å»ºå·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ›å»ºä¸“é¢˜Tag
    create_feature_tag = subparsers.add_parser('create-feature-tag', help='åˆ›å»ºä¸“é¢˜æ•°æ®äº¤ä»˜Tag')
    create_feature_tag.add_argument('topic', help='ä¸»é¢˜åç§° (å¦‚: toll_station)')
    create_feature_tag.add_argument('--date', help='æ—¥æœŸ (YYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©)')
    
    # åˆ›å»ºç‰ˆæœ¬Tag
    create_version_tag = subparsers.add_parser('create-version-tag', help='åˆ›å»ºå¤§ç‰ˆæœ¬Tag')
    create_version_tag.add_argument('version', help='ç‰ˆæœ¬å· (å¦‚: 1.2.0 æˆ– v1.2.0)')
    
    # ç”ŸæˆReleaseè¯´æ˜
    generate_release = subparsers.add_parser('generate-release', help='ç”ŸæˆReleaseè¯´æ˜')
    generate_release.add_argument('version', help='ç‰ˆæœ¬å· (å¦‚: 1.2.0 æˆ– v1.2.0)')
    generate_release.add_argument('--previous', help='ä¸Šä¸€ä¸ªç‰ˆæœ¬å· (ç”¨äºç”Ÿæˆå˜æ›´æ—¥å¿—)')
    
    # åˆ—å‡ºç°æœ‰Tag
    list_tags = subparsers.add_parser('list-tags', help='åˆ—å‡ºç°æœ‰Tag')
    list_tags.add_argument('--pattern', help='Tagåç§°æ¨¡å¼è¿‡æ»¤')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    helper = TagReleaseHelper()
    
    if args.command == 'create-feature-tag':
        helper.create_feature_tag(args.topic, args.date)
    
    elif args.command == 'create-version-tag':
        helper.create_version_tag(args.version)
    
    elif args.command == 'generate-release':
        helper.create_release_draft(args.version, args.previous)
    
    elif args.command == 'list-tags':
        if args.pattern:
            tags = helper._run_git_command(['tag', '-l', args.pattern])
        else:
            tags = helper._run_git_command(['tag', '-l'])
        
        if tags:
            print("ğŸ“‹ ç°æœ‰Tagåˆ—è¡¨:")
            for tag in sorted(tags.split('\n')):
                if tag:
                    print(f"   â€¢ {tag}")
        else:
            print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°Tag")

if __name__ == "__main__":
    main()

